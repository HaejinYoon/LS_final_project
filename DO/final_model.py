"""
ì „ë ¥ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ (3ë¶„í•  ë²„ì „ + 1~2ì›” ì œì™¸ + Validation ë¶„ì„)
- 1~2ì›” ë°ì´í„° ì œì™¸í•˜ê³  í•™ìŠµ (3~11ì›” ë°ì´í„°ë§Œ ì‚¬ìš©)
- íœ´ë¬´ì¼ / ê°€ë™ì¼-ì•¼ê°„ / ê°€ë™ì¼-ì£¼ê°„ 3ê°œë¡œ ë¶„ë¦¬
- ê° ê·¸ë£¹ë³„ë¡œ XGBoost, LightGBM, CatBoost íŠœë‹ (75 trials)
- ì´ 9ê°œ ëª¨ë¸ ì•™ìƒë¸”
- Validation ì¼ì¹˜ë„ ìƒì„¸ ë¶„ì„ ì¶”ê°€
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import xgboost as xgb
from lightgbm import LGBMRegressor
import lightgbm as lgb
from catboost import CatBoostRegressor
import optuna
from scipy.optimize import minimize
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 100)
print("ğŸš€ ì „ë ¥ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ (3ë¶„í•  + 1~2ì›” ì œì™¸ + Validation ë¶„ì„)")
print("=" * 100)

# ============================================================================
# STEP 1: ë°ì´í„° ë¡œë“œ
# ============================================================================
print("\n[STEP 1] ë°ì´í„° ë¡œë“œ")
print("-" * 100)

train = pd.read_csv("./data/raw/train.csv")
test = pd.read_csv("./data/raw/test.csv")

print(f"âœ“ Train shape: {train.shape}")
print(f"âœ“ Test shape: {test.shape}")

# ============================================================================
# STEP 2: ë°ì´í„° ì „ì²˜ë¦¬
# ============================================================================
print("\n[STEP 2] ë°ì´í„° ì „ì²˜ë¦¬")
print("-" * 100)

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
train['ë‹¨ê°€'] = train['ë‹¨ê°€'].fillna(0)

# ì¸¡ì •ì¼ì‹œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
train['ì¸¡ì •ì¼ì‹œ'] = pd.to_datetime(train['ì¸¡ì •ì¼ì‹œ'])
test['ì¸¡ì •ì¼ì‹œ'] = pd.to_datetime(test['ì¸¡ì •ì¼ì‹œ'])

# 1~2ì›” ë°ì´í„° í™•ì¸ ë° ì œì™¸
jan_feb_count = len(train[train['month'].isin([1, 2])])
print(f"\nâœ“ 1~2ì›” ë°ì´í„°: {jan_feb_count}ê±´ ({jan_feb_count/len(train)*100:.1f}%)")

# 1~2ì›” ì œì™¸
train = train[~train['month'].isin([1, 2])].copy()
print(f"âœ“ 1~2ì›” ì œì™¸ í›„ Train shape: {train.shape}")
print(f"âœ“ ì‚¬ìš© ê¸°ê°„: 3~11ì›”")

# íœ´ë¬´ì¼ ì´ìƒì¹˜ ì œê±°
holiday_data = train[train['ì‘ì—…íœ´ë¬´'] == 'íœ´ë¬´'].copy()
Q1 = holiday_data['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'].quantile(0.25)
Q3 = holiday_data['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = ((holiday_data['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'] < lower_bound) | 
            (holiday_data['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'] > upper_bound))
holiday_clean = holiday_data[~outliers]
working_data = train[train['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™'].copy()

train = pd.concat([working_data, holiday_clean], axis=0).sort_values('id').reset_index(drop=True)
print(f"âœ“ ì´ìƒì¹˜ ì œê±°: {outliers.sum()}ê±´")

# ============================================================================
# STEP 3: ê°•í™”ëœ íŒŒìƒë³€ìˆ˜ ìƒì„±
# ============================================================================

def create_enhanced_features(df, is_train=True, train_stats=None):
    """ê°•í™”ëœ íŒŒìƒë³€ìˆ˜ ìƒì„±"""
    df = df.copy()
    
    # === ê¸°ë³¸ ì¸ì½”ë”© ===
    df['ì‹œê°„ëŒ€_ì¸ì½”ë”©'] = (df['ì‹œê°„ëŒ€'] == 'ì£¼ê°„').astype(int)
    df['ì—­ë¥ ê³±_ì—­ìˆ˜'] = 1 / (df['ì§€ìƒì—­ë¥ (%)'] * df['ì§„ìƒì—­ë¥ (%)'] + 1e-10)
    
    ì‹œê°„ëŒ€2_mapping = {
        'ì‹¬ì•¼': 0, 'ì‹¬ì•¼ì „í™˜': 1, 'ì ì‹¬': 2,
        'ì €ë…': 3, 'ì˜¤í›„ê·¼ë¬´': 4, 'ì˜¤ì „ê·¼ë¬´': 5
    }
    df['ì‹œê°„ëŒ€2_ì¸ì½”ë”©'] = df['ì‹œê°„ëŒ€2'].map(ì‹œê°„ëŒ€2_mapping)
    
    ì‘ì—…ìœ í˜•_mapping = {
        'Light_Load': 0, 'Medium_Load': 1, 'Maximum_Load': 2
    }
    df['ì‘ì—…ìœ í˜•_ì¸ì½”ë”©'] = df['ì‘ì—…ìœ í˜•'].map(ì‘ì—…ìœ í˜•_mapping)
    
    # === ì£¼ê¸°ì„± ë³€ìˆ˜ ===
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['day_of_year'] = df['ì¸¡ì •ì¼ì‹œ'].dt.dayofyear
    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)
    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)
    
    # === ê¸°íƒ€ ë³€ìˆ˜ ===
    df['heating_need'] = df['ê¸°ì˜¨'].apply(lambda x: max(0, 15 - x))
    df['ê¸°ì˜¨_hour_interaction'] = df['ê¸°ì˜¨'] * df['hour']
    df['ê¸°ì˜¨_êµ¬ê°„'] = pd.cut(df['ê¸°ì˜¨'], bins=[-20, 0, 10, 20, 40], labels=[0, 1, 2, 3])
    df['ê¸°ì˜¨_êµ¬ê°„'] = df['ê¸°ì˜¨_êµ¬ê°„'].astype(int)
    df['ì‘ì—…ìœ í˜•_hour'] = df['ì‘ì—…ìœ í˜•_ì¸ì½”ë”©'] * df['hour']
    df['ì—­ë¥ ê³±'] = df['ì§€ìƒì—­ë¥ (%)'] * df['ì§„ìƒì—­ë¥ (%)']
    
    # === í†µê³„ ë³€ìˆ˜ (ë¦¬í‚¤ì§€ ë°©ì§€ - 10ì›”ê¹Œì§€ë§Œ ì‚¬ìš©) ===
    if is_train:
        stats = {}
        train_for_stats = df[df['month'] <= 10]
        stats['ì‹œê°„ëŒ€2_í‰ê· ì „ë ¥'] = train_for_stats.groupby('ì‹œê°„ëŒ€2')['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'].mean().to_dict()
        stats['ì‘ì—…ìœ í˜•_í‰ê· ì „ë ¥'] = train_for_stats.groupby('ì‘ì—…ìœ í˜•')['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'].mean().to_dict()
        stats['hour_í‰ê· ì „ë ¥'] = train_for_stats.groupby('hour')['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)'].mean().to_dict()
    else:
        stats = train_stats
    
    df['ì‹œê°„ëŒ€2_í‰ê· ì „ë ¥'] = df['ì‹œê°„ëŒ€2'].map(stats['ì‹œê°„ëŒ€2_í‰ê· ì „ë ¥'])
    df['ì‘ì—…ìœ í˜•_í‰ê· ì „ë ¥'] = df['ì‘ì—…ìœ í˜•'].map(stats['ì‘ì—…ìœ í˜•_í‰ê· ì „ë ¥'])
    df['hour_í‰ê· ì „ë ¥'] = df['hour'].map(stats['hour_í‰ê· ì „ë ¥'])
    
    if is_train:
        return df, stats
    else:
        return df

train_featured, train_stats = create_enhanced_features(train, is_train=True)
test_featured = create_enhanced_features(test, is_train=False, train_stats=train_stats)

# ============================================================================
# STEP 4: Feature ëª©ë¡ ì •ì˜
# ============================================================================

feature_cols = [
    # ê¸°ë³¸ ë³€ìˆ˜
    'month', 'day', 'hour', 'minute', 'ê¸°ì˜¨',
    'ì§€ìƒì—­ë¥ (%)', 'ì§„ìƒì—­ë¥ (%)',
    
    # ê¸°ì¡´ íŒŒìƒë³€ìˆ˜
    'ì‹œê°„ëŒ€_ì¸ì½”ë”©', 'ì—­ë¥ ê³±_ì—­ìˆ˜', 
    'ì‹œê°„ëŒ€2_ì¸ì½”ë”©', 'ì‘ì—…ìœ í˜•_ì¸ì½”ë”©',
    'hour_sin', 'hour_cos', 'heating_need',
    
    # ì£¼ê¸°ì„± ë³€ìˆ˜
    'month_sin', 'month_cos',
    'day_of_year_sin', 'day_of_year_cos',
    
    # ê°•í™” ë³€ìˆ˜
    'ê¸°ì˜¨_hour_interaction', 'ê¸°ì˜¨_êµ¬ê°„',
    'ì‘ì—…ìœ í˜•_hour', 'ì—­ë¥ ê³±',
    
    # í†µê³„ ë³€ìˆ˜
    'ì‹œê°„ëŒ€2_í‰ê· ì „ë ¥', 'ì‘ì—…ìœ í˜•_í‰ê· ì „ë ¥', 'hour_í‰ê· ì „ë ¥'
]


# ============================================================================
# STEP 5: ë°ì´í„° ë¶„í•  (3ë¶„í• )
# ============================================================================
print("\n[STEP 5] ë°ì´í„° ë¶„í•  (ì‹œê°„ìˆœ + 3ë¶„í• )")
print("-" * 100)

train_data = train_featured[train_featured['month'] <= 10].copy()
val_data = train_featured[train_featured['month'] == 11].copy()


# 3ë¶„í• : íœ´ë¬´ì¼ / ê°€ë™ì¼-ì•¼ê°„ / ê°€ë™ì¼-ì£¼ê°„
train_holiday = train_data[train_data['ì‘ì—…íœ´ë¬´'] == 'íœ´ë¬´'].copy()
train_night = train_data[(train_data['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (train_data['ì‹œê°„ëŒ€'] == 'ì•¼ê°„')].copy()
train_day = train_data[(train_data['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (train_data['ì‹œê°„ëŒ€'] == 'ì£¼ê°„')].copy()

val_holiday = val_data[val_data['ì‘ì—…íœ´ë¬´'] == 'íœ´ë¬´'].copy()
val_night = val_data[(val_data['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (val_data['ì‹œê°„ëŒ€'] == 'ì•¼ê°„')].copy()
val_day = val_data[(val_data['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (val_data['ì‹œê°„ëŒ€'] == 'ì£¼ê°„')].copy()


# Featureì™€ Target ë¶„ë¦¬
X_train_holiday = train_holiday[feature_cols]
y_train_holiday = train_holiday['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']
X_val_holiday = val_holiday[feature_cols]
y_val_holiday = val_holiday['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']

X_train_night = train_night[feature_cols]
y_train_night = train_night['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']
X_val_night = val_night[feature_cols]
y_val_night = val_night['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']

X_train_day = train_day[feature_cols]
y_train_day = train_day['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']
X_val_day = val_day[feature_cols]
y_val_day = val_day['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']

# ============================================================================
# STEP 6: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•¨ìˆ˜ ì •ì˜
# ============================================================================
def objective_xgb(trial, X_train, y_train, X_val, y_val):
    params = {
        'objective': 'reg:squarederror',
        'max_depth': trial.suggest_int('max_depth', 6, 12),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 0.5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),
        'random_state': 42,
        'n_jobs': -1
    }
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)
    pred = model.predict(X_val)
    return mean_absolute_error(y_val, pred)

def objective_lgb(trial, X_train, y_train, X_val, y_val):
    params = {
        'objective': 'regression',
        'metric': 'mae',
        'max_depth': trial.suggest_int('max_depth', 5, 15),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),
        'num_leaves': trial.suggest_int('num_leaves', 20, 100),
        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),
        'random_state': 42,
        'n_jobs': -1,
        'verbose': -1
    }
    model = LGBMRegressor(**params)
    model.fit(X_train, y_train, eval_set=[(X_val, y_val)],
              callbacks=[lgb.early_stopping(50, verbose=False)])
    pred = model.predict(X_val)
    return mean_absolute_error(y_val, pred)

def objective_cat(trial, X_train, y_train, X_val, y_val):
    params = {
        'loss_function': 'MAE',
        'iterations': trial.suggest_int('iterations', 500, 2000),
        'depth': trial.suggest_int('depth', 4, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),
        'random_seed': 42,
        'verbose': False
    }
    model = CatBoostRegressor(**params)
    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)
    pred = model.predict(X_val)
    return mean_absolute_error(y_val, pred)

# ============================================================================
# STEP 7: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ì´ 9ê°œ ëª¨ë¸)
# ============================================================================
print("\n[STEP 6] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (XGBoost, LightGBM, CatBoost Ã— 3ê·¸ë£¹)")

# ============== íœ´ë¬´ì¼ ==============
print("\n[1/3] íœ´ë¬´ì¼ íŠœë‹")
print("  XGBoost (75 trials)...")
study_xgb_holiday = optuna.create_study(direction='minimize')
study_xgb_holiday.optimize(
    lambda trial: objective_xgb(trial, X_train_holiday, y_train_holiday, X_val_holiday, y_val_holiday),
    n_trials=75, show_progress_bar=False
)
best_xgb_holiday_params = study_xgb_holiday.best_params
print(f"    âœ“ Best MAE: {study_xgb_holiday.best_value:.4f}")

print("  LightGBM (75 trials)...")
study_lgb_holiday = optuna.create_study(direction='minimize')
study_lgb_holiday.optimize(
    lambda trial: objective_lgb(trial, X_train_holiday, y_train_holiday, X_val_holiday, y_val_holiday),
    n_trials=75, show_progress_bar=False
)
best_lgb_holiday_params = study_lgb_holiday.best_params
print(f"    âœ“ Best MAE: {study_lgb_holiday.best_value:.4f}")

print("  CatBoost (75 trials)...")
study_cat_holiday = optuna.create_study(direction='minimize')
study_cat_holiday.optimize(
    lambda trial: objective_cat(trial, X_train_holiday, y_train_holiday, X_val_holiday, y_val_holiday),
    n_trials=75, show_progress_bar=False
)
best_cat_holiday_params = study_cat_holiday.best_params
print(f"    âœ“ Best MAE: {study_cat_holiday.best_value:.4f}")

# ============== ê°€ë™ì¼-ì•¼ê°„ ==============
print("\n[2/3] ê°€ë™ì¼-ì•¼ê°„ íŠœë‹")
print("  XGBoost (75 trials)...")
study_xgb_night = optuna.create_study(direction='minimize')
study_xgb_night.optimize(
    lambda trial: objective_xgb(trial, X_train_night, y_train_night, X_val_night, y_val_night),
    n_trials=75, show_progress_bar=False
)
best_xgb_night_params = study_xgb_night.best_params
print(f"    âœ“ Best MAE: {study_xgb_night.best_value:.4f}")

print("  LightGBM (75 trials)...")
study_lgb_night = optuna.create_study(direction='minimize')
study_lgb_night.optimize(
    lambda trial: objective_lgb(trial, X_train_night, y_train_night, X_val_night, y_val_night),
    n_trials=75, show_progress_bar=False
)
best_lgb_night_params = study_lgb_night.best_params
print(f"    âœ“ Best MAE: {study_lgb_night.best_value:.4f}")

print("  CatBoost (75 trials)...")
study_cat_night = optuna.create_study(direction='minimize')
study_cat_night.optimize(
    lambda trial: objective_cat(trial, X_train_night, y_train_night, X_val_night, y_val_night),
    n_trials=75, show_progress_bar=False
)
best_cat_night_params = study_cat_night.best_params
print(f"    âœ“ Best MAE: {study_cat_night.best_value:.4f}")

# ============== ê°€ë™ì¼-ì£¼ê°„ ==============
print("\n[3/3] ê°€ë™ì¼-ì£¼ê°„ íŠœë‹")
print("  XGBoost (75 trials)...")
study_xgb_day = optuna.create_study(direction='minimize')
study_xgb_day.optimize(
    lambda trial: objective_xgb(trial, X_train_day, y_train_day, X_val_day, y_val_day),
    n_trials=75, show_progress_bar=False
)
best_xgb_day_params = study_xgb_day.best_params
print(f"    âœ“ Best MAE: {study_xgb_day.best_value:.4f}")

print("  LightGBM (75 trials)...")
study_lgb_day = optuna.create_study(direction='minimize')
study_lgb_day.optimize(
    lambda trial: objective_lgb(trial, X_train_day, y_train_day, X_val_day, y_val_day),
    n_trials=75, show_progress_bar=False
)
best_lgb_day_params = study_lgb_day.best_params
print(f"    âœ“ Best MAE: {study_lgb_day.best_value:.4f}")

print("  CatBoost (75 trials)...")
study_cat_day = optuna.create_study(direction='minimize')
study_cat_day.optimize(
    lambda trial: objective_cat(trial, X_train_day, y_train_day, X_val_day, y_val_day),
    n_trials=75, show_progress_bar=False
)
best_cat_day_params = study_cat_day.best_params
print(f"    âœ“ Best MAE: {study_cat_day.best_value:.4f}")

print("\nâœ“ ì´ 675 trials íŠœë‹ ì™„ë£Œ!")

# ============================================================================
# STEP 8: ìµœì¢… ëª¨ë¸ í•™ìŠµ
# ============================================================================
print("\n[STEP 7] ìµœì¢… ëª¨ë¸ í•™ìŠµ (íŠœë‹ëœ íŒŒë¼ë¯¸í„°)")
print("-" * 100)

# íŒŒë¼ë¯¸í„° ì¤€ë¹„
best_xgb_holiday_params.update({'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1})
best_lgb_holiday_params.update({'objective': 'regression', 'metric': 'mae', 'random_state': 42, 'n_jobs': -1, 'verbose': -1})
best_cat_holiday_params.update({'loss_function': 'MAE', 'random_seed': 42, 'verbose': False})

best_xgb_night_params.update({'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1})
best_lgb_night_params.update({'objective': 'regression', 'metric': 'mae', 'random_state': 42, 'n_jobs': -1, 'verbose': -1})
best_cat_night_params.update({'loss_function': 'MAE', 'random_seed': 42, 'verbose': False})

best_xgb_day_params.update({'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1})
best_lgb_day_params.update({'objective': 'regression', 'metric': 'mae', 'random_state': 42, 'n_jobs': -1, 'verbose': -1})
best_cat_day_params.update({'loss_function': 'MAE', 'random_seed': 42, 'verbose': False})

# íœ´ë¬´ì¼
print("  íœ´ë¬´ì¼ ëª¨ë¸ í•™ìŠµ ì¤‘...")
xgb_holiday = xgb.XGBRegressor(**best_xgb_holiday_params)
xgb_holiday.fit(X_train_holiday, y_train_holiday, eval_set=[(X_val_holiday, y_val_holiday)], verbose=False)

lgb_holiday = LGBMRegressor(**best_lgb_holiday_params)
lgb_holiday.fit(X_train_holiday, y_train_holiday, eval_set=[(X_val_holiday, y_val_holiday)],
                callbacks=[lgb.early_stopping(50, verbose=False)])

cat_holiday = CatBoostRegressor(**best_cat_holiday_params)
cat_holiday.fit(X_train_holiday, y_train_holiday, eval_set=(X_val_holiday, y_val_holiday), verbose=False)

# ê°€ë™ì¼-ì•¼ê°„
print("  ê°€ë™ì¼-ì•¼ê°„ ëª¨ë¸ í•™ìŠµ ì¤‘...")
xgb_night = xgb.XGBRegressor(**best_xgb_night_params)
xgb_night.fit(X_train_night, y_train_night, eval_set=[(X_val_night, y_val_night)], verbose=False)

lgb_night = LGBMRegressor(**best_lgb_night_params)
lgb_night.fit(X_train_night, y_train_night, eval_set=[(X_val_night, y_val_night)],
                callbacks=[lgb.early_stopping(50, verbose=False)])

cat_night = CatBoostRegressor(**best_cat_night_params)
cat_night.fit(X_train_night, y_train_night, eval_set=(X_val_night, y_val_night), verbose=False)

# ê°€ë™ì¼-ì£¼ê°„
print("  ê°€ë™ì¼-ì£¼ê°„ ëª¨ë¸ í•™ìŠµ ì¤‘...")
xgb_day = xgb.XGBRegressor(**best_xgb_day_params)
xgb_day.fit(X_train_day, y_train_day, eval_set=[(X_val_day, y_val_day)], verbose=False)

lgb_day = LGBMRegressor(**best_lgb_day_params)
lgb_day.fit(X_train_day, y_train_day, eval_set=[(X_val_day, y_val_day)],
                callbacks=[lgb.early_stopping(50, verbose=False)])

cat_day = CatBoostRegressor(**best_cat_day_params)
cat_day.fit(X_train_day, y_train_day, eval_set=(X_val_day, y_val_day), verbose=False)

print("âœ“ 9ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# ============================================================================
# STEP 9: ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”
# ============================================================================
print("\n[STEP 8] ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” (3ê·¸ë£¹)")
print("-" * 100)

# ê°œë³„ ì˜ˆì¸¡
pred_xgb_holiday = xgb_holiday.predict(X_val_holiday)
pred_lgb_holiday = lgb_holiday.predict(X_val_holiday)
pred_cat_holiday = cat_holiday.predict(X_val_holiday)

pred_xgb_night = xgb_night.predict(X_val_night)
pred_lgb_night = lgb_night.predict(X_val_night)
pred_cat_night = cat_night.predict(X_val_night)

pred_xgb_day = xgb_day.predict(X_val_day)
pred_lgb_day = lgb_day.predict(X_val_day)
pred_cat_day = cat_day.predict(X_val_day)

# íœ´ë¬´ì¼ ê°€ì¤‘ì¹˜ ìµœì í™”
def objective_weights_holiday(weights):
    pred = weights[0]*pred_xgb_holiday + weights[1]*pred_lgb_holiday + weights[2]*pred_cat_holiday
    return mean_absolute_error(y_val_holiday, pred)

result_holiday = minimize(
    objective_weights_holiday,
    [0.33, 0.33, 0.34],
    bounds=[(0, 1), (0, 1), (0, 1)],
    constraints={'type': 'eq', 'fun': lambda w: sum(w) - 1}
)
optimal_weights_holiday = result_holiday.x

# ê°€ë™ì¼-ì•¼ê°„ ê°€ì¤‘ì¹˜ ìµœì í™”
def objective_weights_night(weights):
    pred = weights[0]*pred_xgb_night + weights[1]*pred_lgb_night + weights[2]*pred_cat_night
    return mean_absolute_error(y_val_night, pred)

result_night = minimize(
    objective_weights_night,
    [0.33, 0.33, 0.34],
    bounds=[(0, 1), (0, 1), (0, 1)],
    constraints={'type': 'eq', 'fun': lambda w: sum(w) - 1}
)
optimal_weights_night = result_night.x

# ê°€ë™ì¼-ì£¼ê°„ ê°€ì¤‘ì¹˜ ìµœì í™”
def objective_weights_day(weights):
    pred = weights[0]*pred_xgb_day + weights[1]*pred_lgb_day + weights[2]*pred_cat_day
    return mean_absolute_error(y_val_day, pred)

result_day = minimize(
    objective_weights_day,
    [0.33, 0.33, 0.34],
    bounds=[(0, 1), (0, 1), (0, 1)],
    constraints={'type': 'eq', 'fun': lambda w: sum(w) - 1}
)
optimal_weights_day = result_day.x

print(f"âœ“ íœ´ë¬´ì¼ ìµœì  ê°€ì¤‘ì¹˜: XGB={optimal_weights_holiday[0]:.3f}, LGB={optimal_weights_holiday[1]:.3f}, CAT={optimal_weights_holiday[2]:.3f}")
print(f"âœ“ ê°€ë™ì¼-ì•¼ê°„ ìµœì  ê°€ì¤‘ì¹˜: XGB={optimal_weights_night[0]:.3f}, LGB={optimal_weights_night[1]:.3f}, CAT={optimal_weights_night[2]:.3f}")
print(f"âœ“ ê°€ë™ì¼-ì£¼ê°„ ìµœì  ê°€ì¤‘ì¹˜: XGB={optimal_weights_day[0]:.3f}, LGB={optimal_weights_day[1]:.3f}, CAT={optimal_weights_day[2]:.3f}")

# ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”
pred_ensemble_holiday = (optimal_weights_holiday[0]*pred_xgb_holiday + 
                          optimal_weights_holiday[1]*pred_lgb_holiday + 
                          optimal_weights_holiday[2]*pred_cat_holiday)

pred_ensemble_night = (optimal_weights_night[0]*pred_xgb_night + 
                        optimal_weights_night[1]*pred_lgb_night + 
                        optimal_weights_night[2]*pred_cat_night)

pred_ensemble_day = (optimal_weights_day[0]*pred_xgb_day + 
                      optimal_weights_day[1]*pred_lgb_day + 
                      optimal_weights_day[2]*pred_cat_day)

# ============================================================================
# STEP 10: ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
# ============================================================================
print("\n[STEP 11] ì „ì²´ Train ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ")
print("-" * 100)

train_full_holiday = train_featured[train_featured['ì‘ì—…íœ´ë¬´'] == 'íœ´ë¬´'].copy()
train_full_night = train_featured[(train_featured['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (train_featured['ì‹œê°„ëŒ€'] == 'ì•¼ê°„')].copy()
train_full_day = train_featured[(train_featured['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (train_featured['ì‹œê°„ëŒ€'] == 'ì£¼ê°„')].copy()

X_full_holiday = train_full_holiday[feature_cols]
y_full_holiday = train_full_holiday['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']
X_full_night = train_full_night[feature_cols]
y_full_night = train_full_night['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']
X_full_day = train_full_day[feature_cols]
y_full_day = train_full_day['ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)']

# íœ´ë¬´ì¼
print("  íœ´ë¬´ì¼ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
final_xgb_holiday = xgb.XGBRegressor(**best_xgb_holiday_params)
final_xgb_holiday.fit(X_full_holiday, y_full_holiday, verbose=False)

final_lgb_holiday = LGBMRegressor(**best_lgb_holiday_params)
final_lgb_holiday.fit(X_full_holiday, y_full_holiday)

final_cat_holiday = CatBoostRegressor(**best_cat_holiday_params)
final_cat_holiday.fit(X_full_holiday, y_full_holiday, verbose=False)

# ê°€ë™ì¼-ì•¼ê°„
print("  ê°€ë™ì¼-ì•¼ê°„ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
final_xgb_night = xgb.XGBRegressor(**best_xgb_night_params)
final_xgb_night.fit(X_full_night, y_full_night, verbose=False)

final_lgb_night = LGBMRegressor(**best_lgb_night_params)
final_lgb_night.fit(X_full_night, y_full_night)

final_cat_night = CatBoostRegressor(**best_cat_night_params)
final_cat_night.fit(X_full_night, y_full_night, verbose=False)

# ê°€ë™ì¼-ì£¼ê°„
print("  ê°€ë™ì¼-ì£¼ê°„ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
final_xgb_day = xgb.XGBRegressor(**best_xgb_day_params)
final_xgb_day.fit(X_full_day, y_full_day, verbose=False)

final_lgb_day = LGBMRegressor(**best_lgb_day_params)
final_lgb_day.fit(X_full_day, y_full_day)

final_cat_day = CatBoostRegressor(**best_cat_day_params)
final_cat_day.fit(X_full_day, y_full_day, verbose=False)

print("âœ“ ìµœì¢… 9ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

# ============================================================================
# STEP 11: Test ë°ì´í„° ì˜ˆì¸¡
# ============================================================================
print("\n[STEP 12] Test ë°ì´í„° ì˜ˆì¸¡")
print("-" * 100)

test_holiday = test_featured[test_featured['ì‘ì—…íœ´ë¬´'] == 'íœ´ë¬´'].copy()
test_night = test_featured[(test_featured['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (test_featured['ì‹œê°„ëŒ€'] == 'ì•¼ê°„')].copy()
test_day = test_featured[(test_featured['ì‘ì—…íœ´ë¬´'] == 'ê°€ë™') & (test_featured['ì‹œê°„ëŒ€'] == 'ì£¼ê°„')].copy()

X_test_holiday = test_holiday[feature_cols]
X_test_night = test_night[feature_cols]
X_test_day = test_day[feature_cols]

# ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
pred_test_xgb_holiday = final_xgb_holiday.predict(X_test_holiday)
pred_test_lgb_holiday = final_lgb_holiday.predict(X_test_holiday)
pred_test_cat_holiday = final_cat_holiday.predict(X_test_holiday)

pred_test_xgb_night = final_xgb_night.predict(X_test_night)
pred_test_lgb_night = final_lgb_night.predict(X_test_night)
pred_test_cat_night = final_cat_night.predict(X_test_night)

pred_test_xgb_day = final_xgb_day.predict(X_test_day)
pred_test_lgb_day = final_lgb_day.predict(X_test_day)
pred_test_cat_day = final_cat_day.predict(X_test_day)

# ìµœì  ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”
pred_test_holiday = (optimal_weights_holiday[0]*pred_test_xgb_holiday + 
                      optimal_weights_holiday[1]*pred_test_lgb_holiday + 
                      optimal_weights_holiday[2]*pred_test_cat_holiday)

pred_test_night = (optimal_weights_night[0]*pred_test_xgb_night + 
                    optimal_weights_night[1]*pred_test_lgb_night + 
                    optimal_weights_night[2]*pred_test_cat_night)

pred_test_day = (optimal_weights_day[0]*pred_test_xgb_day + 
                  optimal_weights_day[1]*pred_test_lgb_day + 
                  optimal_weights_day[2]*pred_test_cat_day)

print(f"âœ“ íœ´ë¬´ì¼ ì˜ˆì¸¡ ì™„ë£Œ: {len(pred_test_holiday)}ê°œ")
print(f"âœ“ ê°€ë™ì¼-ì•¼ê°„ ì˜ˆì¸¡ ì™„ë£Œ: {len(pred_test_night)}ê°œ")
print(f"âœ“ ê°€ë™ì¼-ì£¼ê°„ ì˜ˆì¸¡ ì™„ë£Œ: {len(pred_test_day)}ê°œ")

# ============================================================================
# STEP 12: í›„ì²˜ë¦¬
# ============================================================================

# ì‹¤ì œ CSV ê¸°ë°˜ íšŒê·€ ê³„ìˆ˜ (1Â·2Â·11ì›” fitting ê²°ê³¼)
worktype_params = {
    "Light_Load":   {"a": 15.088489, "b": 1_072_302.0},
    "Medium_Load":  {"a": 2.404026,  "b": 1_096_892.0},
    "Maximum_Load": {"a": 2.732438,  "b": 1_107_024.0},
}

def predict_unit_price_by_work(work_type, lag_pf, lead_pf):
    """
    ì‘ì—…ìœ í˜•ë³„ ê¸°ë³¸ì‹ íšŒê·€ê³„ìˆ˜ì— ë”°ë¼ ë‹¨ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
    ì…ë ¥ê°’:
        work_type : str ('Light_Load' / 'Medium_Load' / 'Maximum_Load')
        lag_pf    : float (ì§€ìƒì—­ë¥  %, ì˜ˆ: 90.5)
        lead_pf   : float (ì§„ìƒì—­ë¥  %, ì˜ˆ: 95.0)
    
    ë°˜í™˜ê°’:
        ì˜ˆì¸¡ ë‹¨ê°€ (float)
    """
    if work_type not in worktype_params:
        raise ValueError(f"'{work_type}'ì€(ëŠ”) ìœ íš¨í•œ ì‘ì—…ìœ í˜•ì´ ì•„ë‹™ë‹ˆë‹¤. "
                         f"í—ˆìš©ê°’: {list(worktype_params.keys())}")
    
    a = worktype_params[work_type]["a"]
    b = worktype_params[work_type]["b"]
    # ì—­ë¥ ê³± ì—­ìˆ˜ ê³„ì‚° (0ë°©ì§€)
    inv_pf = 1.0 / max(lag_pf * lead_pf, 1e-6)
    
    # ë‹¨ê°€ ê³„ì‚°
    price = a + b * inv_pf
    return round(price, 3)


# ì˜ˆì¸¡ê°’ í›„ì²˜ë¦¬
pred_test_holiday = np.maximum(pred_test_holiday, 0)
pred_test_night = np.maximum(pred_test_night, 0)
pred_test_day = np.maximum(pred_test_day, 0)

pred_test_holiday = np.minimum(pred_test_holiday, 5.0)
pred_test_night = np.minimum(pred_test_night, 15.0)

print("âœ“ í›„ì²˜ë¦¬ ì™„ë£Œ")
print(f"  - íœ´ë¬´ì¼: [0, 5] kWh")
print(f"  - ì•¼ê°„: [0, 15] kWh")
print(f"  - ì£¼ê°„: [0, ~] kWh")

# ì˜ˆì¸¡ê°’ì„ ê° ë°ì´í„°í”„ë ˆì„ì— í• ë‹¹
test_holiday['ì „ë ¥ì‚¬ìš©ëŸ‰'] = pred_test_holiday
test_night['ì „ë ¥ì‚¬ìš©ëŸ‰'] = pred_test_night
test_day['ì „ë ¥ì‚¬ìš©ëŸ‰'] = pred_test_day

# concat ë¨¼ì € ìˆ˜í–‰
test_result = pd.concat([test_holiday, test_night, test_day]).sort_values('id').reset_index(drop=True)


# ============================================================================
# STEP 13: ì „ê¸°ìš”ê¸ˆ ê³„ì‚° ë° Submission
# ============================================================================
print("\n[STEP 15] ì „ê¸°ìš”ê¸ˆ ê³„ì‚° ë° Submission ìƒì„±")
print("-" * 100)

# ë‹¨ê°€ ê³„ì‚° (í•œ ë²ˆë§Œ)

# ì‘ì—…ìœ í˜•ë³„ ë‹¨ê°€ ê³„ì‚°
test_result['ë‹¨ê°€'] = test_result.apply(
    lambda row: predict_unit_price_by_work(
        row['ì‘ì—…ìœ í˜•'], 
        row['ì§€ìƒì—­ë¥ (%)'], 
        row['ì§„ìƒì—­ë¥ (%)']
    ), 
    axis=1
)

print("âœ“ ì‘ì—…ìœ í˜•ë³„ ë‹¨ê°€ ê³„ì‚° ì™„ë£Œ")
print(f"  - Light_Load í‰ê· : {test_result[test_result['ì‘ì—…ìœ í˜•']=='Light_Load']['ë‹¨ê°€'].mean():.2f} ì›/kWh")
print(f"  - Medium_Load í‰ê· : {test_result[test_result['ì‘ì—…ìœ í˜•']=='Medium_Load']['ë‹¨ê°€'].mean():.2f} ì›/kWh")
print(f"  - Maximum_Load í‰ê· : {test_result[test_result['ì‘ì—…ìœ í˜•']=='Maximum_Load']['ë‹¨ê°€'].mean():.2f} ì›/kWh")

# ì „ê¸°ìš”ê¸ˆ ê³„ì‚°
test_result['ì „ê¸°ìš”ê¸ˆ'] = test_result['ì „ë ¥ì‚¬ìš©ëŸ‰'] * test_result['ë‹¨ê°€']

print("âœ“ ì „ê¸°ìš”ê¸ˆ ê³„ì‚° ì™„ë£Œ")


submission = pd.DataFrame({
    'id': test_result['id'],
    'target': test_result['ì „ê¸°ìš”ê¸ˆ']
})

submission.to_csv('subë³´ì •ì™„ë£Œ1.csv', index=False)
